
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>Sparse recovery: feature selection for sparse linear models &#8212; scikit-learn 0.18.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../../_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.18.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="top" title="scikit-learn 0.18.1 documentation" href="../../index.html" />
    <link rel="up" title="Examples" href="../index.html" />
    <link rel="next" title="Swiss Roll reduction with LLE" href="../manifold/plot_swissroll.html" />
    <link rel="prev" title="Lasso model selection: Cross-Validation / AIC / BIC" href="plot_lasso_model_selection.html" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../../_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_recovery.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
  </script>

  </head>
  <body role="document">

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar">
            <ul>
                <li><a href="../../index.html">主页</a></li>
                <li><a href="../../install.html">安装</a></li>
                <li class="btn-li"><div class="btn-group">
              <a href="../../documentation.html">文档</a>
              <a class="btn dropdown-toggle" data-toggle="dropdown">
                 <span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
            <li class="link-title">Scikit-learn 0.17 (stable)</li>
            <li><a href="../../tutorial/index.html">入门指南</a></li>
            <li><a href="../../user_guide.html">使用手册</a></li>
            <li><a href="../../modules/classes.html">API</a></li>
            <li><a href="../../faq.html">FAQ</a></li>
            <li><a href="../../developers.html">贡献</a></li>
            <li class="divider"></li>
                <li><a href="http://scikit-learn.org/dev/documentation.html">Scikit-learn 0.18 (development)</a></li>
                <li><a href="http://scikit-learn.org/0.16/documentation.html">Scikit-learn 0.16</a></li>
				<li><a href="../../_downloads/user_guide.pdf">PDF 文档</a></li>
              </ul>
            </div>
        </li>
            <li><a href="../index.html">例子</a></li>
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/lzjqsdd/scikit-learn-doc-cn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="plot_lasso_model_selection.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        Lasso model s...
        </span>
            <span class="hiddenrellink">
            Lasso model selection: Cross-Validation / AIC / BIC
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="../index.html">
        Up
        <br/>
        <span class="smallrellink">
        Examples
        </span>
            <span class="hiddenrellink">
            Examples
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version">This documentation is for scikit-learn <strong>version 0.18.1</strong> &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    <p class="citing">If you use the software, please consider <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <ul>
<li><a class="reference internal" href="#">Sparse recovery: feature selection for sparse linear models</a></li>
</ul>

    </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="sparse-recovery-feature-selection-for-sparse-linear-models">
<span id="example-linear-model-plot-sparse-recovery-py"></span><h1>Sparse recovery: feature selection for sparse linear models<a class="headerlink" href="#sparse-recovery-feature-selection-for-sparse-linear-models" title="Permalink to this headline">¶</a></h1>
<p>Given a small number of observations, we want to recover which features
of X are relevant to explain y. For this <a class="reference internal" href="../../modules/feature_selection.html#l1-feature-selection"><span class="std std-ref">sparse linear models</span></a> can outperform standard statistical tests if the
true model is sparse, i.e. if a small fraction of the features are
relevant.</p>
<p>As detailed in <a class="reference internal" href="../../modules/feature_selection.html#compressive-sensing"><span class="std std-ref">the compressive sensing notes</span></a>, the ability of L1-based approach to identify the
relevant variables depends on the sparsity of the ground truth, the
number of samples, the number of features, the conditioning of the
design matrix on the signal subspace, the amount of noise, and the
absolute value of the smallest non-zero coefficient [Wainwright2006]
(<a class="reference external" href="http://statistics.berkeley.edu/tech-reports/709.pdf">http://statistics.berkeley.edu/tech-reports/709.pdf</a>).</p>
<p>Here we keep all parameters constant and vary the conditioning of the
design matrix. For a well-conditioned design matrix (small mutual
incoherence) we are exactly in compressive sensing conditions (i.i.d
Gaussian sensing matrix), and L1-recovery with the Lasso performs very
well. For an ill-conditioned matrix (high mutual incoherence),
regressors are very correlated, and the Lasso randomly selects one.
However, randomized-Lasso can recover the ground truth well.</p>
<p>In each situation, we first vary the alpha parameter setting the sparsity
of the estimated model and look at the stability scores of the randomized
Lasso. This analysis, knowing the ground truth, shows an optimal regime
in which relevant features stand out from the irrelevant ones. If alpha
is chosen too small, non-relevant variables enter the model. On the
opposite, if alpha is selected too large, the Lasso is equivalent to
stepwise regression, and thus brings no advantage over a univariate
F-test.</p>
<p>In a second time, we set alpha and compare the performance of different
feature selection methods, using the area under curve (AUC) of the
precision-recall.</p>
<ul class="horizontal">
<li><a class="first reference internal image-reference" href="../../_images/plot_sparse_recovery_001.png"><img alt="../../_images/plot_sparse_recovery_001.png" src="../../_images/plot_sparse_recovery_001.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../../_images/plot_sparse_recovery_002.png"><img alt="../../_images/plot_sparse_recovery_002.png" src="../../_images/plot_sparse_recovery_002.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../../_images/plot_sparse_recovery_003.png"><img alt="../../_images/plot_sparse_recovery_003.png" src="../../_images/plot_sparse_recovery_003.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
<li><a class="first reference internal image-reference" href="../../_images/plot_sparse_recovery_004.png"><img alt="../../_images/plot_sparse_recovery_004.png" src="../../_images/plot_sparse_recovery_004.png" style="width: 376.0px; height: 282.0px;" /></a>
</li>
</ul>
<p><strong>Python source code:</strong> <a class="reference download internal" href="../../_downloads/plot_sparse_recovery.py" download=""><code class="xref download docutils literal"><span class="pre">plot_sparse_recovery.py</span></code></a></p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">__doc__</span><span class="p">)</span>

<span class="c1"># Author: Alexandre Gramfort and Gael Varoquaux</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">linalg</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="p">(</span><a href="../../modules/generated/sklearn.linear_model.RandomizedLasso.html#sklearn.linear_model.RandomizedLasso"><span class="n">RandomizedLasso</span></a><span class="p">,</span> <a href="../../modules/generated/sklearn.linear_model.lasso_stability_path.html#sklearn.linear_model.lasso_stability_path"><span class="n">lasso_stability_path</span></a><span class="p">,</span>
                                  <a href="../../modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV"><span class="n">LassoLarsCV</span></a><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="k">import</span> <a href="../../modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression"><span class="n">f_regression</span></a>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="k">import</span> <a href="../../modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"><span class="n">StandardScaler</span></a>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <a href="../../modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc"><span class="n">auc</span></a><span class="p">,</span> <a href="../../modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve"><span class="n">precision_recall_curve</span></a>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="k">import</span> <a href="../../modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor"><span class="n">ExtraTreesRegressor</span></a>
<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="k">import</span> <span class="n">pinvh</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="k">import</span> <span class="n">ConvergenceWarning</span>


<span class="k">def</span> <span class="nf">mutual_incoherence</span><span class="p">(</span><span class="n">X_relevant</span><span class="p">,</span> <span class="n">X_irelevant</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Mutual incoherence, as defined by formula (26a) of [Wainwright2006].</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">projector</span> <span class="o">=</span> <a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.dot.html#numpy.dot"><span class="n">np</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span><a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.dot.html#numpy.dot"><span class="n">np</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span><span class="n">X_irelevant</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X_relevant</span><span class="p">),</span>
                       <span class="n">pinvh</span><span class="p">(</span><a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.dot.html#numpy.dot"><span class="n">np</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span><span class="n">X_relevant</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X_relevant</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">projector</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>


<span class="k">for</span> <span class="n">conditioning</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span><span class="p">):</span>
    <span class="c1">###########################################################################</span>
    <span class="c1"># Simulate regression data with a correlated design</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="mi">501</span>
    <span class="n">n_relevant_features</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">noise_level</span> <span class="o">=</span> <span class="o">.</span><span class="mi">2</span>
    <span class="n">coef_min</span> <span class="o">=</span> <span class="o">.</span><span class="mi">2</span>
    <span class="c1"># The Donoho-Tanner phase transition is around n_samples=25: below we</span>
    <span class="c1"># will completely fail to recover in the well-conditioned case</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">25</span>
    <span class="n">block_size</span> <span class="o">=</span> <span class="n">n_relevant_features</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1"># The coefficients of our model</span>
    <span class="n">coef</span> <span class="o">=</span> <a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.zeros.html#numpy.zeros"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">(</span><span class="n">n_features</span><span class="p">)</span>
    <span class="n">coef</span><span class="p">[:</span><span class="n">n_relevant_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">coef_min</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">n_relevant_features</span><span class="p">)</span>

    <span class="c1"># The correlation of our design: variables correlated by blocs of 3</span>
    <span class="n">corr</span> <span class="o">=</span> <a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.zeros.html#numpy.zeros"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">((</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">block_size</span><span class="p">):</span>
        <span class="n">corr</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">,</span> <span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">conditioning</span>
    <span class="n">corr</span><span class="o">.</span><span class="n">flat</span><span class="p">[::</span><span class="n">n_features</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">corr</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">corr</span><span class="p">)</span>

    <span class="c1"># Our design</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">))</span>
    <span class="n">X</span> <span class="o">=</span> <a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.dot.html#numpy.dot"><span class="n">np</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">corr</span><span class="p">)</span>
    <span class="c1"># Keep [Wainwright2006] (26c) constant</span>
    <span class="n">X</span><span class="p">[:</span><span class="n">n_relevant_features</span><span class="p">]</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span>
        <a href="http://docs.scipy.org/doc/scipy-0.11.0/reference/generated/scipy.linalg.svdvals.html#scipy.linalg.svdvals"><span class="n">linalg</span><span class="o">.</span><span class="n">svdvals</span></a><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="n">n_relevant_features</span><span class="p">]))</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">X</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"><span class="n">StandardScaler</span></a><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>

    <span class="c1"># The output variable</span>
    <span class="n">y</span> <span class="o">=</span> <a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.dot.html#numpy.dot"><span class="n">np</span><span class="o">.</span><span class="n">dot</span></a><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">/=</span> <a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.std.html#numpy.std"><span class="n">np</span><span class="o">.</span><span class="n">std</span></a><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="c1"># We scale the added noise as a function of the average correlation</span>
    <span class="c1"># between the design and the output variable</span>
    <span class="n">y</span> <span class="o">+=</span> <span class="n">noise_level</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="n">mi</span> <span class="o">=</span> <span class="n">mutual_incoherence</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="n">n_relevant_features</span><span class="p">],</span>
                            <span class="n">X</span><span class="p">[:,</span> <span class="n">n_relevant_features</span><span class="p">:])</span>

    <span class="c1">###########################################################################</span>
    <span class="c1"># Plot stability selection path, using a high eps for early stopping</span>
    <span class="c1"># of the path, to save computation time</span>
    <span class="n">alpha_grid</span><span class="p">,</span> <span class="n">scores_path</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.linear_model.lasso_stability_path.html#sklearn.linear_model.lasso_stability_path"><span class="n">lasso_stability_path</span></a><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                                                   <span class="n">eps</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

    <a href="http://matplotlib.org/api/figure_api.html#matplotlib.figure"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">()</span>
    <span class="c1"># We plot the path as a function of alpha/alpha_max to the power 1/3: the</span>
    <span class="c1"># power 1/3 scales the path less brutally than the log, and enables to</span>
    <span class="c1"># see the progression along the path</span>
    <span class="n">hg</span> <span class="o">=</span> <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">alpha_grid</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">**</span> <span class="o">.</span><span class="mi">333</span><span class="p">,</span> <span class="n">scores_path</span><span class="p">[</span><span class="n">coef</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
    <span class="n">hb</span> <span class="o">=</span> <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><span class="n">alpha_grid</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">**</span> <span class="o">.</span><span class="mi">333</span><span class="p">,</span> <span class="n">scores_path</span><span class="p">[</span><span class="n">coef</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.ylim"><span class="n">plt</span><span class="o">.</span><span class="n">ylim</span></a><span class="p">()</span>
    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.xlabel"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span></a><span class="p">(</span><span class="s1">r&#39;$(\alpha / \alpha_</span><span class="si">{max}</span><span class="s1">)^{1/3}$&#39;</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.ylabel"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span></a><span class="p">(</span><span class="s1">&#39;Stability score: proportion of times selected&#39;</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.title"><span class="n">plt</span><span class="o">.</span><span class="n">title</span></a><span class="p">(</span><span class="s1">&#39;Stability Scores Path - Mutual incoherence: </span><span class="si">%.1f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">mi</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/axis_api.html#matplotlib.axis"><span class="n">plt</span><span class="o">.</span><span class="n">axis</span></a><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/legend_api.html#matplotlib.legend"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span></a><span class="p">((</span><span class="n">hg</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">hb</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="p">(</span><span class="s1">&#39;relevant features&#39;</span><span class="p">,</span> <span class="s1">&#39;irrelevant features&#39;</span><span class="p">),</span>
               <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>

    <span class="c1">###########################################################################</span>
    <span class="c1"># Plot the estimated stability scores for a given alpha</span>

    <span class="c1"># Use 6-fold cross-validation rather than the default 3-fold: it leads to</span>
    <span class="c1"># a better choice of alpha:</span>
    <span class="c1"># Stop the user warnings outputs- they are not necessary for the example</span>
    <span class="c1"># as it is specifically set up to be challenging.</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="ne">UserWarning</span><span class="p">)</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">ConvergenceWarning</span><span class="p">)</span>
        <span class="n">lars_cv</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV"><span class="n">LassoLarsCV</span></a><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Run the RandomizedLasso: we use a paths going down to .1*alpha_max</span>
    <span class="c1"># to avoid exploring the regime in which very noisy variables enter</span>
    <span class="c1"># the model</span>
    <span class="n">alphas</span> <span class="o">=</span> <a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.linspace.html#numpy.linspace"><span class="n">np</span><span class="o">.</span><span class="n">linspace</span></a><span class="p">(</span><span class="n">lars_cv</span><span class="o">.</span><span class="n">alphas_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">.</span><span class="mi">1</span> <span class="o">*</span> <span class="n">lars_cv</span><span class="o">.</span><span class="n">alphas_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">6</span><span class="p">)</span>
    <span class="n">clf</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.linear_model.RandomizedLasso.html#sklearn.linear_model.RandomizedLasso"><span class="n">RandomizedLasso</span></a><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">trees</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor"><span class="n">ExtraTreesRegressor</span></a><span class="p">(</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="c1"># Compare with F-score</span>
    <span class="n">F</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression"><span class="n">f_regression</span></a><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <a href="http://matplotlib.org/api/figure_api.html#matplotlib.figure"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">()</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="p">[(</span><span class="s1">&#39;F-test&#39;</span><span class="p">,</span> <span class="n">F</span><span class="p">),</span>
                        <span class="p">(</span><span class="s1">&#39;Stability selection&#39;</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">scores_</span><span class="p">),</span>
                        <span class="p">(</span><span class="s1">&#39;Lasso coefs&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">lars_cv</span><span class="o">.</span><span class="n">coef_</span><span class="p">)),</span>
                        <span class="p">(</span><span class="s1">&#39;Trees&#39;</span><span class="p">,</span> <span class="n">trees</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">),</span>
                        <span class="p">]:</span>
        <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <a href="../../modules/generated/sklearn.metrics.precision_recall_curve.html#sklearn.metrics.precision_recall_curve"><span class="n">precision_recall_curve</span></a><span class="p">(</span><span class="n">coef</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span>
                                                               <span class="n">score</span><span class="p">)</span>
        <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.semilogy"><span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span></a><span class="p">(</span><a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.maximum.html#numpy.maximum"><span class="n">np</span><span class="o">.</span><span class="n">maximum</span></a><span class="p">(</span><span class="n">score</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">score</span><span class="p">),</span> <span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span><span class="p">),</span>
                     <span class="n">label</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">. AUC: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <a href="../../modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc"><span class="n">auc</span></a><span class="p">(</span><span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">)))</span>

    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot"><span class="n">plt</span><span class="o">.</span><span class="n">plot</span></a><span class="p">(</span><a href="http://docs.scipy.org/doc/numpy-1.6.0/reference/generated/numpy.where.html#numpy.where"><span class="n">np</span><span class="o">.</span><span class="n">where</span></a><span class="p">(</span><span class="n">coef</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="n">e</span><span class="o">-</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_relevant_features</span><span class="p">,</span> <span class="s1">&#39;mo&#39;</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ground truth&quot;</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.xlabel"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span></a><span class="p">(</span><span class="s2">&quot;Features&quot;</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.ylabel"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span></a><span class="p">(</span><span class="s2">&quot;Score&quot;</span><span class="p">)</span>
    <span class="c1"># Plot only the 100 first coefficients</span>
    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.xlim"><span class="n">plt</span><span class="o">.</span><span class="n">xlim</span></a><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/legend_api.html#matplotlib.legend"><span class="n">plt</span><span class="o">.</span><span class="n">legend</span></a><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
    <a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.title"><span class="n">plt</span><span class="o">.</span><span class="n">title</span></a><span class="p">(</span><span class="s1">&#39;Feature selection scores - Mutual incoherence: </span><span class="si">%.1f</span><span class="s1">&#39;</span>
              <span class="o">%</span> <span class="n">mi</span><span class="p">)</span>

<a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.show"><span class="n">plt</span><span class="o">.</span><span class="n">show</span></a><span class="p">()</span>
</pre></div>
</div>
<p><strong>Total running time of the example:</strong>  7.33 seconds
( 0 minutes  7.33 seconds)</p>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010 - 2014, scikit-learn developers (BSD License).
      <a href="../../_sources/auto_examples/linear_model/plot_sparse_recovery.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="plot_lasso_model_selection.html">Previous
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>