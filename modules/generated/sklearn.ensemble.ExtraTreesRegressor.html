
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>3.2.4.3.4. sklearn.ensemble.ExtraTreesRegressor &#8212; scikit-learn 0.18.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../../_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.18.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="top" title="scikit-learn 0.18.1 documentation" href="../../index.html" />
    <link rel="up" title="3.2. Grid Search: Searching for estimator parameters" href="../grid_search.html" />
    <link rel="next" title="3.2.4.3.5. sklearn.ensemble.GradientBoostingClassifier" href="sklearn.ensemble.GradientBoostingClassifier.html" />
    <link rel="prev" title="3.2.4.3.3. sklearn.ensemble.ExtraTreesClassifier" href="sklearn.ensemble.ExtraTreesClassifier.html" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../../_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
  </script>

  </head>
  <body role="document">

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar">
            <ul>
                <li><a href="../../index.html">主页</a></li>
                <li><a href="../../install.html">安装</a></li>
                <li class="btn-li"><div class="btn-group">
              <a href="../../documentation.html">文档</a>
              <a class="btn dropdown-toggle" data-toggle="dropdown">
                 <span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
            <li class="link-title">Scikit-learn 0.17 (stable)</li>
            <li><a href="../../tutorial/index.html">入门指南</a></li>
            <li><a href="../../user_guide.html">使用手册</a></li>
            <li><a href="../classes.html">API</a></li>
            <li><a href="../../faq.html">FAQ</a></li>
            <li><a href="../../developers.html">贡献</a></li>
            <li class="divider"></li>
                <li><a href="http://scikit-learn.org/dev/documentation.html">Scikit-learn 0.18 (development)</a></li>
                <li><a href="http://scikit-learn.org/0.16/documentation.html">Scikit-learn 0.16</a></li>
				<li><a href="../../_downloads/user_guide.pdf">PDF 文档</a></li>
              </ul>
            </div>
        </li>
            <li><a href="../../auto_examples/index.html">例子</a></li>
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/lzjqsdd/scikit-learn-doc-cn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="sklearn.ensemble.ExtraTreesClassifier.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        3.2.4.3.3. sk...
        </span>
            <span class="hiddenrellink">
            3.2.4.3.3. sklearn.ensemble.ExtraTreesClassifier
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="../grid_search.html">
        Up
        <br/>
        <span class="smallrellink">
        3.2. Grid Sea...
        </span>
            <span class="hiddenrellink">
            3.2. Grid Search: Searching for estimator parameters
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version">This documentation is for scikit-learn <strong>version 0.18.1</strong> &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    <p class="citing">If you use the software, please consider <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <ul>
<li><a class="reference internal" href="#">3.2.4.3.4. <code class="docutils literal"><span class="pre">sklearn.ensemble</span></code>.ExtraTreesRegressor</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-ensemble-extratreesregressor">3.2.4.3.4.1. Examples using <code class="docutils literal"><span class="pre">sklearn.ensemble.ExtraTreesRegressor</span></code></a></li>
</ul>
</li>
</ul>

    </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="sklearn-ensemble-extratreesregressor">
<h1>3.2.4.3.4. <a class="reference internal" href="../classes.html#module-sklearn.ensemble" title="sklearn.ensemble"><code class="xref py py-mod docutils literal"><span class="pre">sklearn.ensemble</span></code></a>.ExtraTreesRegressor<a class="headerlink" href="#sklearn-ensemble-extratreesregressor" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.ensemble.ExtraTreesRegressor">
<em class="property">class </em><code class="descclassname">sklearn.ensemble.</code><code class="descname">ExtraTreesRegressor</code><span class="sig-paren">(</span><em>n_estimators=10</em>, <em>criterion='mse'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_weight_fraction_leaf=0.0</em>, <em>max_features='auto'</em>, <em>max_leaf_nodes=None</em>, <em>min_impurity_split=1e-07</em>, <em>bootstrap=False</em>, <em>oob_score=False</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>verbose=0</em>, <em>warm_start=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/ensemble/forest.py#L1337"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor" title="Permalink to this definition">¶</a></dt>
<dd><p>An extra-trees regressor.</p>
<p>This class implements a meta estimator that fits a number of
randomized decision trees (a.k.a. extra-trees) on various sub-samples
of the dataset and use averaging to improve the predictive accuracy
and control over-fitting.</p>
<p>Read more in the <a class="reference internal" href="../ensemble.html#forest"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>n_estimators</strong> : integer, optional (default=10)</p>
<blockquote>
<div><p>The number of trees in the forest.</p>
</div></blockquote>
<p><strong>criterion</strong> : string, optional (default=&#8221;mse&#8221;)</p>
<blockquote>
<div><p>The function to measure the quality of a split. Supported criteria
are &#8220;mse&#8221; for the mean squared error, which is equal to variance
reduction as feature selection criterion, and &#8220;mae&#8221; for the mean
absolute error.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.18: </span>Mean Absolute Error (MAE) criterion.</p>
</div>
</div></blockquote>
<p><strong>max_features</strong> : int, float, string or None, optional (default=&#8221;auto&#8221;)</p>
<blockquote>
<div><p>The number of features to consider when looking for the best split:</p>
<ul class="simple">
<li>If int, then consider <cite>max_features</cite> features at each split.</li>
<li>If float, then <cite>max_features</cite> is a percentage and
<cite>int(max_features * n_features)</cite> features are considered at each
split.</li>
<li>If &#8220;auto&#8221;, then <cite>max_features=n_features</cite>.</li>
<li>If &#8220;sqrt&#8221;, then <cite>max_features=sqrt(n_features)</cite>.</li>
<li>If &#8220;log2&#8221;, then <cite>max_features=log2(n_features)</cite>.</li>
<li>If None, then <cite>max_features=n_features</cite>.</li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal"><span class="pre">max_features</span></code> features.</p>
</div></blockquote>
<p><strong>max_depth</strong> : integer or None, optional (default=None)</p>
<blockquote>
<div><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</div></blockquote>
<p><strong>min_samples_split</strong> : int, float, optional (default=2)</p>
<blockquote>
<div><p>The minimum number of samples required to split an internal node:</p>
<ul class="simple">
<li>If int, then consider <cite>min_samples_split</cite> as the minimum number.</li>
<li>If float, then <cite>min_samples_split</cite> is a percentage and
<cite>ceil(min_samples_split * n_samples)</cite> are the minimum
number of samples for each split.</li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified">Changed in version 0.18: </span>Added float values for percentages.</p>
</div>
</div></blockquote>
<p><strong>min_samples_leaf</strong> : int, float, optional (default=1)</p>
<blockquote>
<div><p>The minimum number of samples required to be at a leaf node:</p>
<ul class="simple">
<li>If int, then consider <cite>min_samples_leaf</cite> as the minimum number.</li>
<li>If float, then <cite>min_samples_leaf</cite> is a percentage and
<cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum
number of samples for each node.</li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified">Changed in version 0.18: </span>Added float values for percentages.</p>
</div>
</div></blockquote>
<p><strong>min_weight_fraction_leaf</strong> : float, optional (default=0.)</p>
<blockquote>
<div><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</div></blockquote>
<p><strong>max_leaf_nodes</strong> : int or None, optional (default=None)</p>
<blockquote>
<div><p>Grow trees with <code class="docutils literal"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</div></blockquote>
<p><strong>min_impurity_split</strong> : float, optional (default=1e-7)</p>
<blockquote>
<div><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.18.</span></p>
</div>
</div></blockquote>
<p><strong>bootstrap</strong> : boolean, optional (default=False)</p>
<blockquote>
<div><p>Whether bootstrap samples are used when building trees.</p>
</div></blockquote>
<p><strong>oob_score</strong> : bool, optional (default=False)</p>
<blockquote>
<div><p>Whether to use out-of-bag samples to estimate the R^2 on unseen data.</p>
</div></blockquote>
<p><strong>n_jobs</strong> : integer, optional (default=1)</p>
<blockquote>
<div><p>The number of jobs to run in parallel for both <cite>fit</cite> and <cite>predict</cite>.
If -1, then the number of jobs is set to the number of cores.</p>
</div></blockquote>
<p><strong>random_state</strong> : int, RandomState instance or None, optional (default=None)</p>
<blockquote>
<div><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p>
</div></blockquote>
<p><strong>verbose</strong> : int, optional (default=0)</p>
<blockquote>
<div><p>Controls the verbosity of the tree building process.</p>
</div></blockquote>
<p><strong>warm_start</strong> : bool, optional (default=False)</p>
<blockquote>
<div><p>When set to <code class="docutils literal"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Attributes:</th><td class="field-body"><p class="first"><strong>estimators_</strong> : list of DecisionTreeRegressor</p>
<blockquote>
<div><p>The collection of fitted sub-estimators.</p>
</div></blockquote>
<p><strong>feature_importances_</strong> : array of shape = [n_features]</p>
<blockquote>
<div><p>The feature importances (the higher, the more important the feature).</p>
</div></blockquote>
<p><strong>n_features_</strong> : int</p>
<blockquote>
<div><p>The number of features.</p>
</div></blockquote>
<p><strong>n_outputs_</strong> : int</p>
<blockquote>
<div><p>The number of outputs.</p>
</div></blockquote>
<p><strong>oob_score_</strong> : float</p>
<blockquote>
<div><p>Score of the training dataset obtained using an out-of-bag estimate.</p>
</div></blockquote>
<p><strong>oob_prediction_</strong> : array of shape = [n_samples]</p>
<blockquote class="last">
<div><p>Prediction computed with out-of-bag estimate on the training set.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference internal" href="sklearn.tree.ExtraTreeRegressor.html#sklearn.tree.ExtraTreeRegressor" title="sklearn.tree.ExtraTreeRegressor"><code class="xref py py-obj docutils literal"><span class="pre">sklearn.tree.ExtraTreeRegressor</span></code></a></dt>
<dd>Base estimator for this ensemble.</dd>
<dt><a class="reference internal" href="sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor"><code class="xref py py-obj docutils literal"><span class="pre">RandomForestRegressor</span></code></a></dt>
<dd>Ensemble regressor using trees with optimal splits.</dd>
</dl>
</div>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r136" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[R136]</a></td><td>P. Geurts, D. Ernst., and L. Wehenkel, &#8220;Extremely randomized trees&#8221;,
Machine Learning, 63(1), 3-42, 2006.</td></tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.apply" title="sklearn.ensemble.ExtraTreesRegressor.apply"><code class="xref py py-obj docutils literal"><span class="pre">apply</span></code></a>(X)</td>
<td>Apply trees in the forest to X, return leaf indices.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.decision_path" title="sklearn.ensemble.ExtraTreesRegressor.decision_path"><code class="xref py py-obj docutils literal"><span class="pre">decision_path</span></code></a>(X)</td>
<td>Return the decision path in the forest</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.fit" title="sklearn.ensemble.ExtraTreesRegressor.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Build a forest of trees from the training set (X, y).</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.fit_transform" title="sklearn.ensemble.ExtraTreesRegressor.fit_transform"><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code></a>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.get_params" title="sklearn.ensemble.ExtraTreesRegressor.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.predict" title="sklearn.ensemble.ExtraTreesRegressor.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(X)</td>
<td>Predict regression target for X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.score" title="sklearn.ensemble.ExtraTreesRegressor.score"><code class="xref py py-obj docutils literal"><span class="pre">score</span></code></a>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Returns the coefficient of determination R^2 of the prediction.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.set_params" title="sklearn.ensemble.ExtraTreesRegressor.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(\*\*params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.ensemble.ExtraTreesRegressor.transform" title="sklearn.ensemble.ExtraTreesRegressor.transform"><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code></a>(\*args,&nbsp;\*\*kwargs)</td>
<td>DEPRECATED: Support to use estimators as feature selectors will be removed in version 0.19.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>n_estimators=10</em>, <em>criterion='mse'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>min_weight_fraction_leaf=0.0</em>, <em>max_features='auto'</em>, <em>max_leaf_nodes=None</em>, <em>min_impurity_split=1e-07</em>, <em>bootstrap=False</em>, <em>oob_score=False</em>, <em>n_jobs=1</em>, <em>random_state=None</em>, <em>verbose=0</em>, <em>warm_start=False</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/ensemble/forest.py#L1475"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.apply">
<code class="descname">apply</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/ensemble/forest.py#L160"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply trees in the forest to X, return leaf indices.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like or sparse matrix, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>The input samples. Internally, its dtype will be converted to
<code class="docutils literal"><span class="pre">dtype=np.float32</span></code>. If a sparse matrix is provided, it will be
converted into a sparse <code class="docutils literal"><span class="pre">csr_matrix</span></code>.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_leaves</strong> : array_like, shape = [n_samples, n_estimators]</p>
<blockquote class="last">
<div><p>For each datapoint x in X and for each tree in the forest,
return the index of the leaf x ends up in.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.decision_path">
<code class="descname">decision_path</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/ensemble/forest.py#L184"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.decision_path" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the decision path in the forest</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.18.</span></p>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like or sparse matrix, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>The input samples. Internally, its dtype will be converted to
<code class="docutils literal"><span class="pre">dtype=np.float32</span></code>. If a sparse matrix is provided, it will be
converted into a sparse <code class="docutils literal"><span class="pre">csr_matrix</span></code>.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>indicator</strong> : sparse csr array, shape = [n_samples, n_nodes]</p>
<blockquote>
<div><p>Return a node indicator matrix where non zero elements
indicates that the samples goes through the nodes.</p>
</div></blockquote>
<p><strong>n_nodes_ptr</strong> : array of size (n_estimators + 1, )</p>
<blockquote class="last">
<div><p>The columns from indicator[n_nodes_ptr[i]:n_nodes_ptr[i+1]]
gives the indicator value for the i-th estimator.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="sklearn.ensemble.ExtraTreesRegressor.feature_importances_">
<code class="descname">feature_importances_</code><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.feature_importances_" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Return the feature importances (the higher, the more important the</dt>
<dd>feature).</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>feature_importances_</strong> : array, shape = [n_features]</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/ensemble/forest.py#L220"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Build a forest of trees from the training set (X, y).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like or sparse matrix of shape = [n_samples, n_features]</p>
<blockquote>
<div><p>The training input samples. Internally, its dtype will be converted to
<code class="docutils literal"><span class="pre">dtype=np.float32</span></code>. If a sparse matrix is provided, it will be
converted into a sparse <code class="docutils literal"><span class="pre">csc_matrix</span></code>.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = [n_samples] or [n_samples, n_outputs]</p>
<blockquote>
<div><p>The target values (class labels in classification, real numbers in
regression).</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples] or None</p>
<blockquote>
<div><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> : object</p>
<blockquote class="last">
<div><p>Returns self.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>**fit_params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L470"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : numpy array of shape [n_samples, n_features]</p>
<blockquote>
<div><p>Training set.</p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>
<blockquote class="last">
<div><p>Transformed array.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L220"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/ensemble/forest.py#L666"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict regression target for X.</p>
<p>The predicted regression target of an input sample is computed as the
mean predicted regression targets of the trees in the forest.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like or sparse matrix of shape = [n_samples, n_features]</p>
<blockquote>
<div><p>The input samples. Internally, its dtype will be converted to
<code class="docutils literal"><span class="pre">dtype=np.float32</span></code>. If a sparse matrix is provided, it will be
converted into a sparse <code class="docutils literal"><span class="pre">csr_matrix</span></code>.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>y</strong> : array of shape = [n_samples] or [n_samples, n_outputs]</p>
<blockquote class="last">
<div><p>The predicted values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L357"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the coefficient of determination R^2 of the prediction.</p>
<p>The coefficient R^2 is defined as (1 - u/v), where u is the regression
sum of squares ((y_true - y_pred) ** 2).sum() and v is the residual
sum of squares ((y_true - y_true.mean()) ** 2).sum().
Best possible score is 1.0 and it can be negative (because the
model can be arbitrarily worse). A constant model that always
predicts the expected value of y, disregarding the input features,
would get a R^2 score of 0.0.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>
<blockquote>
<div><p>Test samples.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>
<blockquote>
<div><p>True values for X.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>
<blockquote>
<div><p>Sample weights.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>R^2 of self.predict(X) wrt. y.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L257"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> :</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.ensemble.ExtraTreesRegressor.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/utils/deprecation.py#L69"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.ensemble.ExtraTreesRegressor.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>DEPRECATED: Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.</p>
<p>Reduce X to its most important features.</p>
<blockquote>
<div>Uses <code class="docutils literal"><span class="pre">coef_</span></code> or <code class="docutils literal"><span class="pre">feature_importances_</span></code> to determine the most
important features.  For models with a <code class="docutils literal"><span class="pre">coef_</span></code> for each class, the
absolute sum over the classes is used.</div></blockquote>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array or scipy sparse matrix of shape [n_samples, n_features]</p>
<blockquote>
<div><blockquote>
<div><p>The input samples.</p>
</div></blockquote>
<dl class="docutils">
<dt>threshold</dt>
 <span class="classifier-delimiter">:</span> <span class="classifier">string, float or None, optional (default=None)</span><dd><p class="first last">The threshold value to use for feature selection. Features whose
importance is greater or equal are kept while the others are
discarded. If &#8220;median&#8221; (resp. &#8220;mean&#8221;), then the threshold value is
the median (resp. the mean) of the feature importances. A scaling
factor (e.g., &#8220;1.25*mean&#8221;) may also be used. If None and if
available, the object attribute <code class="docutils literal"><span class="pre">threshold</span></code> is used. Otherwise,
&#8220;mean&#8221; is used by default.</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_r</strong> : array of shape [n_samples, n_selected_features]</p>
<blockquote class="last">
<div><p>The input samples with only the selected features.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-sklearn-ensemble-extratreesregressor">
<h2>3.2.4.3.4.1. Examples using <code class="docutils literal"><span class="pre">sklearn.ensemble.ExtraTreesRegressor</span></code><a class="headerlink" href="#examples-using-sklearn-ensemble-extratreesregressor" title="Permalink to this headline">¶</a></h2>
<div class="thumbnailContainer" tooltip="This example shows the use of multi-output estimator to complete images. The goal is to predict..."><div class="figure" id="id2">
<a class="reference external image-reference" href="./../../auto_examples/./plot_multioutput_face_completion.html"><img alt="../../_images/plot_multioutput_face_completion1.png" src="../../_images/plot_multioutput_face_completion1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/plot_multioutput_face_completion.html#example-plot-multioutput-face-completion-py"><span class="std std-ref">Face completion with a multi-output estimators</span></a></span></p>
</div>
</div><div class="thumbnailContainer" tooltip="Given a small number of observations, we want to recover which features of X are relevant to ex..."><div class="figure" id="id3">
<a class="reference external image-reference" href="./../../auto_examples/linear_model/plot_sparse_recovery.html"><img alt="../../_images/plot_sparse_recovery1.png" src="../../_images/plot_sparse_recovery1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/linear_model/plot_sparse_recovery.html#example-linear-model-plot-sparse-recovery-py"><span class="std std-ref">Sparse recovery: feature selection for sparse linear models</span></a></span></p>
</div>
</div><div class="clearer"></div></div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010 - 2014, scikit-learn developers (BSD License).
      <a href="../../_sources/modules/generated/sklearn.ensemble.ExtraTreesRegressor.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="sklearn.ensemble.ExtraTreesClassifier.html">Previous
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>