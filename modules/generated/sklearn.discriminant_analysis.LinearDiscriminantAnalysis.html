
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>sklearn.discriminant_analysis.LinearDiscriminantAnalysis &#8212; scikit-learn 0.18.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../../_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.18.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="top" title="scikit-learn 0.18.1 documentation" href="../../index.html" />
    <link rel="up" title="API ?ο?" href="../classes.html" />
    <link rel="next" title="sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis" href="sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html" />
    <link rel="prev" title="sklearn.kernel_ridge.KernelRidge" href="sklearn.kernel_ridge.KernelRidge.html" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../../_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
  </script>

  </head>
  <body role="document">

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar">
            <ul>
                <li><a href="../../index.html">主页</a></li>
                <li><a href="../../install.html">安装</a></li>
                <li class="btn-li"><div class="btn-group">
              <a href="../../documentation.html">文档</a>
              <a class="btn dropdown-toggle" data-toggle="dropdown">
                 <span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
            <li class="link-title">Scikit-learn 0.17 (stable)</li>
            <li><a href="../../tutorial/index.html">入门指南</a></li>
            <li><a href="../../user_guide.html">使用手册</a></li>
            <li><a href="../classes.html">API</a></li>
            <li><a href="../../faq.html">FAQ</a></li>
            <li><a href="../../developers.html">贡献</a></li>
            <li class="divider"></li>
                <li><a href="http://scikit-learn.org/dev/documentation.html">Scikit-learn 0.18 (development)</a></li>
                <li><a href="http://scikit-learn.org/0.16/documentation.html">Scikit-learn 0.16</a></li>
				<li><a href="../../_downloads/user_guide.pdf">PDF 文档</a></li>
              </ul>
            </div>
        </li>
            <li><a href="../../auto_examples/index.html">例子</a></li>
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/lzjqsdd/scikit-learn-doc-cn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="sklearn.kernel_ridge.KernelRidge.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        sklearn.kerne...
        </span>
            <span class="hiddenrellink">
            sklearn.kernel_ridge.KernelRidge
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="../classes.html">
        Up
        <br/>
        <span class="smallrellink">
        API ?ο?
        </span>
            <span class="hiddenrellink">
            API ?ο?
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version">This documentation is for scikit-learn <strong>version 0.18.1</strong> &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    <p class="citing">If you use the software, please consider <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <ul>
<li><a class="reference internal" href="#"><code class="docutils literal"><span class="pre">sklearn.discriminant_analysis</span></code>.LinearDiscriminantAnalysis</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-discriminant-analysis-lineardiscriminantanalysis">Examples using <code class="docutils literal"><span class="pre">sklearn.discriminant_analysis.LinearDiscriminantAnalysis</span></code></a></li>
</ul>
</li>
</ul>

    </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="sklearn-discriminant-analysis-lineardiscriminantanalysis">
<h1><a class="reference internal" href="../classes.html#module-sklearn.discriminant_analysis" title="sklearn.discriminant_analysis"><code class="xref py py-mod docutils literal"><span class="pre">sklearn.discriminant_analysis</span></code></a>.LinearDiscriminantAnalysis<a class="headerlink" href="#sklearn-discriminant-analysis-lineardiscriminantanalysis" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis">
<em class="property">class </em><code class="descclassname">sklearn.discriminant_analysis.</code><code class="descname">LinearDiscriminantAnalysis</code><span class="sig-paren">(</span><em>solver='svd'</em>, <em>shrinkage=None</em>, <em>priors=None</em>, <em>n_components=None</em>, <em>store_covariance=False</em>, <em>tol=0.0001</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/discriminant_analysis.py#L130"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear Discriminant Analysis</p>
<p>A classifier with a linear decision boundary, generated by fitting class
conditional densities to the data and using Bayes&#8217; rule.</p>
<p>The model fits a Gaussian density to each class, assuming that all classes
share the same covariance matrix.</p>
<p>The fitted model can also be used to reduce the dimensionality of the input
by projecting it to the most discriminative directions.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17: </span><em>LinearDiscriminantAnalysis</em>.</p>
</div>
<p>Read more in the <a class="reference internal" href="../lda_qda.html#lda-qda"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>solver</strong> : string, optional</p>
<blockquote>
<div><dl class="docutils">
<dt>Solver to use, possible values:</dt>
<dd><ul class="first last simple">
<li>&#8216;svd&#8217;: Singular value decomposition (default).
Does not compute the covariance matrix, therefore this solver is
recommended for data with a large number of features.</li>
<li>&#8216;lsqr&#8217;: Least squares solution, can be combined with shrinkage.</li>
<li>&#8216;eigen&#8217;: Eigenvalue decomposition, can be combined with shrinkage.</li>
</ul>
</dd>
</dl>
</div></blockquote>
<p><strong>shrinkage</strong> : string or float, optional</p>
<blockquote>
<div><dl class="docutils">
<dt>Shrinkage parameter, possible values:</dt>
<dd><ul class="first last simple">
<li>None: no shrinkage (default).</li>
<li>&#8216;auto&#8217;: automatic shrinkage using the Ledoit-Wolf lemma.</li>
<li>float between 0 and 1: fixed shrinkage parameter.</li>
</ul>
</dd>
</dl>
<p>Note that shrinkage works only with &#8216;lsqr&#8217; and &#8216;eigen&#8217; solvers.</p>
</div></blockquote>
<p><strong>priors</strong> : array, optional, shape (n_classes,)</p>
<blockquote>
<div><p>Class priors.</p>
</div></blockquote>
<p><strong>n_components</strong> : int, optional</p>
<blockquote>
<div><p>Number of components (&lt; n_classes - 1) for dimensionality reduction.</p>
</div></blockquote>
<p><strong>store_covariance</strong> : bool, optional</p>
<blockquote>
<div><p>Additionally compute class covariance matrix (default False).</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17.</span></p>
</div>
</div></blockquote>
<p><strong>tol</strong> : float, optional</p>
<blockquote>
<div><p>Threshold used for rank estimation in SVD solver.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17.</span></p>
</div>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Attributes:</th><td class="field-body"><p class="first"><strong>coef_</strong> : array, shape (n_features,) or (n_classes, n_features)</p>
<blockquote>
<div><p>Weight vector(s).</p>
</div></blockquote>
<p><strong>intercept_</strong> : array, shape (n_features,)</p>
<blockquote>
<div><p>Intercept term.</p>
</div></blockquote>
<p><strong>covariance_</strong> : array-like, shape (n_features, n_features)</p>
<blockquote>
<div><p>Covariance matrix (shared by all classes).</p>
</div></blockquote>
<p><strong>explained_variance_ratio_</strong> : array, shape (n_components,)</p>
<blockquote>
<div><p>Percentage of variance explained by each of the selected components.
If <code class="docutils literal"><span class="pre">n_components</span></code> is not set then all components are stored and the
sum of explained variances is equal to 1.0. Only available when eigen
or svd solver is used.</p>
</div></blockquote>
<p><strong>means_</strong> : array-like, shape (n_classes, n_features)</p>
<blockquote>
<div><p>Class means.</p>
</div></blockquote>
<p><strong>priors_</strong> : array-like, shape (n_classes,)</p>
<blockquote>
<div><p>Class priors (sum to 1).</p>
</div></blockquote>
<p><strong>scalings_</strong> : array-like, shape (rank, n_classes - 1)</p>
<blockquote>
<div><p>Scaling of the features in the space spanned by the class centroids.</p>
</div></blockquote>
<p><strong>xbar_</strong> : array-like, shape (n_features,)</p>
<blockquote>
<div><p>Overall mean.</p>
</div></blockquote>
<p><strong>classes_</strong> : array-like, shape (n_classes,)</p>
<blockquote class="last">
<div><p>Unique class labels.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><a class="reference internal" href="sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis" title="sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis"><code class="xref py py-obj docutils literal"><span class="pre">sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis</span></code></a></dt>
<dd>Quadratic Discriminant Analysis</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The default solver is &#8216;svd&#8217;. It can perform both classification and
transform, and it does not rely on the calculation of the covariance
matrix. This can be an advantage in situations where the number of features
is large. However, the &#8216;svd&#8217; solver cannot be used with shrinkage.</p>
<p>The &#8216;lsqr&#8217; solver is an efficient algorithm that only works for
classification. It supports shrinkage.</p>
<p>The &#8216;eigen&#8217; solver is based on the optimization of the between class
scatter to within class scatter ratio. It can be used for both
classification and transform, and it supports shrinkage. However, the
&#8216;eigen&#8217; solver needs to compute the covariance matrix, so it might not be
suitable for situations with a high number of features.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="k">import</span> <span class="n">LinearDiscriminantAnalysis</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,</span>
<span class="go">              solver=&#39;svd&#39;, store_covariance=False, tol=0.0001)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.8</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]))</span>
<span class="go">[1]</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function"><code class="xref py py-obj docutils literal"><span class="pre">decision_function</span></code></a>(X)</td>
<td>Predict confidence scores for samples.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y[,&nbsp;store_covariance,&nbsp;tol])</td>
<td>Fit LinearDiscriminantAnalysis model according to the given    training data and parameters.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform"><code class="xref py py-obj docutils literal"><span class="pre">fit_transform</span></code></a>(X[,&nbsp;y])</td>
<td>Fit to data, then transform it.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(X)</td>
<td>Predict class labels for samples in X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_log_proba</span></code></a>(X)</td>
<td>Estimate log probability.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(X)</td>
<td>Estimate probability.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score"><code class="xref py py-obj docutils literal"><span class="pre">score</span></code></a>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Returns the mean accuracy on the given test data and labels.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(\*\*params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform" title="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform"><code class="xref py py-obj docutils literal"><span class="pre">transform</span></code></a>(X)</td>
<td>Project data to maximize class separation.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>solver='svd'</em>, <em>shrinkage=None</em>, <em>priors=None</em>, <em>n_components=None</em>, <em>store_covariance=False</em>, <em>tol=0.0001</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/discriminant_analysis.py#L248"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/linear_model/base.py#L290"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict confidence scores for samples.</p>
<p>The confidence score for a sample is the signed distance of that
sample to the hyperplane.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = (n_samples, n_features)</p>
<blockquote>
<div><p>Samples.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)</strong> :</p>
<blockquote class="last">
<div><p>Confidence scores per (sample, class) combination. In the binary
case, confidence score for self.classes_[1] where &gt;0 means this
class would be predicted.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>store_covariance=None</em>, <em>tol=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/discriminant_analysis.py#L410"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit" title="Permalink to this definition">¶</a></dt>
<dd><dl class="docutils">
<dt>Fit LinearDiscriminantAnalysis model according to the given</dt>
<dd><p class="first">training data and parameters.</p>
<div class="versionchanged">
<p><span class="versionmodified">Changed in version 0.17: </span>Deprecated <em>store_covariance</em> have been moved to main constructor.</p>
</div>
<div class="last versionchanged">
<p><span class="versionmodified">Changed in version 0.17: </span>Deprecated <em>tol</em> have been moved to main constructor.</p>
</div>
</dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>
<blockquote>
<div><p>Training data.</p>
</div></blockquote>
<p><strong>y</strong> : array, shape (n_samples,)</p>
<blockquote class="last">
<div><p>Target values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>X</em>, <em>y=None</em>, <em>**fit_params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L470"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit to data, then transform it.</p>
<p>Fits transformer to X and y with optional parameters fit_params
and returns a transformed version of X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : numpy array of shape [n_samples, n_features]</p>
<blockquote>
<div><p>Training set.</p>
</div></blockquote>
<p><strong>y</strong> : numpy array of shape [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_new</strong> : numpy array of shape [n_samples, n_features_new]</p>
<blockquote class="last">
<div><p>Transformed array.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L220"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/linear_model/base.py#L323"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict class labels for samples in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Samples.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>C</strong> : array, shape = [n_samples]</p>
<blockquote class="last">
<div><p>Predicted class label per sample.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/discriminant_analysis.py#L533"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate log probability.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>
<blockquote>
<div><p>Input data.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>C</strong> : array, shape (n_samples, n_classes)</p>
<blockquote class="last">
<div><p>Estimated log probabilities.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/discriminant_analysis.py#L508"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate probability.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>
<blockquote>
<div><p>Input data.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>C</strong> : array, shape (n_samples, n_classes)</p>
<blockquote class="last">
<div><p>Estimated probabilities.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L324"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>
<blockquote>
<div><p>Test samples.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>
<blockquote>
<div><p>True labels for X.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>
<blockquote>
<div><p>Sample weights.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>Mean accuracy of self.predict(X) wrt. y.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L257"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> :</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/discriminant_analysis.py#L482"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Project data to maximize class separation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape (n_samples, n_features)</p>
<blockquote>
<div><p>Input data.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>X_new</strong> : array, shape (n_samples, n_components)</p>
<blockquote class="last">
<div><p>Transformed data.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-sklearn-discriminant-analysis-lineardiscriminantanalysis">
<h2>Examples using <code class="docutils literal"><span class="pre">sklearn.discriminant_analysis.LinearDiscriminantAnalysis</span></code><a class="headerlink" href="#examples-using-sklearn-discriminant-analysis-lineardiscriminantanalysis" title="Permalink to this headline">¶</a></h2>
<div class="thumbnailContainer" tooltip="Shows how shrinkage improves classification. "><div class="figure" id="id1">
<a class="reference external image-reference" href="./../../auto_examples/classification/plot_lda.html"><img alt="../../_images/plot_lda1.png" src="../../_images/plot_lda1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/classification/plot_lda.html#example-classification-plot-lda-py"><span class="std std-ref">Normal and Shrinkage Linear Discriminant Analysis for classification</span></a></span></p>
</div>
</div><div class="thumbnailContainer" tooltip="A comparison of a several classifiers in scikit-learn on synthetic datasets. The point of this ..."><div class="figure" id="id2">
<a class="reference external image-reference" href="./../../auto_examples/classification/plot_classifier_comparison.html"><img alt="../../_images/plot_classifier_comparison1.png" src="../../_images/plot_classifier_comparison1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/classification/plot_classifier_comparison.html#example-classification-plot-classifier-comparison-py"><span class="std std-ref">Classifier comparison</span></a></span></p>
</div>
</div><div class="thumbnailContainer" tooltip="Plot the confidence ellipsoids of each class and decision boundary "><div class="figure" id="id3">
<a class="reference external image-reference" href="./../../auto_examples/classification/plot_lda_qda.html"><img alt="../../_images/plot_lda_qda1.png" src="../../_images/plot_lda_qda1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/classification/plot_lda_qda.html#example-classification-plot-lda-qda-py"><span class="std std-ref">Linear and Quadratic Discriminant Analysis with confidence ellipsoid</span></a></span></p>
</div>
</div><div class="thumbnailContainer" tooltip="The Iris dataset represents 3 kind of Iris flowers (Setosa, Versicolour and Virginica) with 4 a..."><div class="figure" id="id4">
<a class="reference external image-reference" href="./../../auto_examples/decomposition/plot_pca_vs_lda.html"><img alt="../../_images/plot_pca_vs_lda1.png" src="../../_images/plot_pca_vs_lda1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/decomposition/plot_pca_vs_lda.html#example-decomposition-plot-pca-vs-lda-py"><span class="std std-ref">Comparison of LDA and PCA 2D projection of Iris dataset</span></a></span></p>
</div>
</div><div class="thumbnailContainer" tooltip="An illustration of various embeddings on the digits dataset."><div class="figure" id="id5">
<a class="reference external image-reference" href="./../../auto_examples/manifold/plot_lle_digits.html"><img alt="../../_images/plot_lle_digits1.png" src="../../_images/plot_lle_digits1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/manifold/plot_lle_digits.html#example-manifold-plot-lle-digits-py"><span class="std std-ref">Manifold learning on handwritten digits: Locally Linear Embedding, Isomap...</span></a></span></p>
</div>
</div><div class="clearer"></div></div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010 - 2014, scikit-learn developers (BSD License).
      <a href="../../_sources/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="sklearn.kernel_ridge.KernelRidge.html">Previous
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>