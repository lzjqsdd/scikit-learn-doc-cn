
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
  
    <title>sklearn.naive_bayes.MultinomialNB &#8212; scikit-learn 0.18.1 documentation</title>
  <!-- htmltitle is before nature.css - we use this hack to load bootstrap first -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="../../_static/css/bootstrap.min.css" media="screen" />
  <link rel="stylesheet" href="../../_static/css/bootstrap-responsive.css"/>

    
    <link rel="stylesheet" href="../../_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.18.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/js/copybutton.js"></script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="top" title="scikit-learn 0.18.1 documentation" href="../../index.html" />
    <link rel="up" title="API ?ο?" href="../classes.html" />
    <link rel="next" title="sklearn.naive_bayes.BernoulliNB" href="sklearn.naive_bayes.BernoulliNB.html" />
    <link rel="prev" title="sklearn.naive_bayes.GaussianNB" href="sklearn.naive_bayes.GaussianNB.html" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <script src="../../_static/js/bootstrap.min.js" type="text/javascript"></script>
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html" />

  <script type="text/javascript">
    $("div.buttonNext, div.buttonPrevious").hover(
       function () {
           $(this).css('background-color', '#FF9C34');
       },
       function () {
           $(this).css('background-color', '#A7D6E2');
       }
    );
  </script>

  </head>
  <body role="document">

<div class="header-wrapper">
    <div class="header">
        <p class="logo"><a href="../../index.html">
            <img src="../../_static/scikit-learn-logo-small.png" alt="Logo"/>
        </a>
        </p><div class="navbar">
            <ul>
                <li><a href="../../index.html">主页</a></li>
                <li><a href="../../install.html">安装</a></li>
                <li class="btn-li"><div class="btn-group">
              <a href="../../documentation.html">文档</a>
              <a class="btn dropdown-toggle" data-toggle="dropdown">
                 <span class="caret"></span>
              </a>
              <ul class="dropdown-menu">
            <li class="link-title">Scikit-learn 0.17 (stable)</li>
            <li><a href="../../tutorial/index.html">入门指南</a></li>
            <li><a href="../../user_guide.html">使用手册</a></li>
            <li><a href="../classes.html">API</a></li>
            <li><a href="../../faq.html">FAQ</a></li>
            <li><a href="../../developers.html">贡献</a></li>
            <li class="divider"></li>
                <li><a href="http://scikit-learn.org/dev/documentation.html">Scikit-learn 0.18 (development)</a></li>
                <li><a href="http://scikit-learn.org/0.16/documentation.html">Scikit-learn 0.16</a></li>
				<li><a href="../../_downloads/user_guide.pdf">PDF 文档</a></li>
              </ul>
            </div>
        </li>
            <li><a href="../../auto_examples/index.html">例子</a></li>
            </ul>

            <div class="search_form">
                <div id="cse" style="width: 100%;"></div>
            </div>
        </div> <!-- end navbar --></div>
</div>


<!-- Github "fork me" ribbon -->
<a href="https://github.com/lzjqsdd/scikit-learn-doc-cn">
  <img class="fork-me"
       style="position: absolute; top: 0; right: 0; border: 0;"
       src="../../_static/img/forkme.png"
       alt="Fork me on GitHub" />
</a>

<div class="content-wrapper">
    <div class="sphinxsidebar">
    <div class="sphinxsidebarwrapper">
        <div class="rel">
    

  <!-- rellinks[1:] is an ugly hack to avoid link to module
  index -->
        <div class="rellink">
        <a href="sklearn.naive_bayes.GaussianNB.html"
        accesskey="P">Previous
        <br/>
        <span class="smallrellink">
        sklearn.naive...
        </span>
            <span class="hiddenrellink">
            sklearn.naive_bayes.GaussianNB
            </span>
        </a>
        </div>

    <!-- Ad a link to the 'up' page -->
        <div class="spacer">
        &nbsp;
        </div>
        <div class="rellink">
        <a href="../classes.html">
        Up
        <br/>
        <span class="smallrellink">
        API ?ο?
        </span>
            <span class="hiddenrellink">
            API ?ο?
            </span>
            
        </a>
        </div>
    </div>
    
      <p class="doc-version">This documentation is for scikit-learn <strong>version 0.18.1</strong> &mdash; <a href="http://scikit-learn.org/stable/support.html#documentation-resources">Other versions</a></p>
    <p class="citing">If you use the software, please consider <a href="../../about.html#citing-scikit-learn">citing scikit-learn</a>.</p>
    <ul>
<li><a class="reference internal" href="#"><code class="docutils literal"><span class="pre">sklearn.naive_bayes</span></code>.MultinomialNB</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-naive-bayes-multinomialnb">Examples using <code class="docutils literal"><span class="pre">sklearn.naive_bayes.MultinomialNB</span></code></a></li>
</ul>
</li>
</ul>

    </div>
</div>

<input type="checkbox" id="nav-trigger" class="nav-trigger" checked />
<label for="nav-trigger"></label>




      <div class="content">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="sklearn-naive-bayes-multinomialnb">
<h1><a class="reference internal" href="../classes.html#module-sklearn.naive_bayes" title="sklearn.naive_bayes"><code class="xref py py-mod docutils literal"><span class="pre">sklearn.naive_bayes</span></code></a>.MultinomialNB<a class="headerlink" href="#sklearn-naive-bayes-multinomialnb" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="sklearn.naive_bayes.MultinomialNB">
<em class="property">class </em><code class="descclassname">sklearn.naive_bayes.</code><code class="descname">MultinomialNB</code><span class="sig-paren">(</span><em>alpha=1.0</em>, <em>fit_prior=True</em>, <em>class_prior=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/naive_bayes.py#L606"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB" title="Permalink to this definition">¶</a></dt>
<dd><p>Naive Bayes classifier for multinomial models</p>
<p>The multinomial Naive Bayes classifier is suitable for classification with
discrete features (e.g., word counts for text classification). The
multinomial distribution normally requires integer feature counts. However,
in practice, fractional counts such as tf-idf may also work.</p>
<p>Read more in the <a class="reference internal" href="../naive_bayes.html#multinomial-naive-bayes"><span class="std std-ref">User Guide</span></a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>alpha</strong> : float, optional (default=1.0)</p>
<blockquote>
<div><p>Additive (Laplace/Lidstone) smoothing parameter
(0 for no smoothing).</p>
</div></blockquote>
<p><strong>fit_prior</strong> : boolean, optional (default=True)</p>
<blockquote>
<div><p>Whether to learn class prior probabilities or not.
If false, a uniform prior will be used.</p>
</div></blockquote>
<p><strong>class_prior</strong> : array-like, size (n_classes,), optional (default=None)</p>
<blockquote>
<div><p>Prior probabilities of the classes. If specified the priors are not
adjusted according to the data.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Attributes:</th><td class="field-body"><p class="first"><strong>class_log_prior_</strong> : array, shape (n_classes, )</p>
<blockquote>
<div><p>Smoothed empirical log probability for each class.</p>
</div></blockquote>
<p><strong>intercept_</strong> : property</p>
<blockquote>
<div><p>Mirrors <code class="docutils literal"><span class="pre">class_log_prior_</span></code> for interpreting MultinomialNB
as a linear model.</p>
</div></blockquote>
<p><strong>feature_log_prob_</strong> : array, shape (n_classes, n_features)</p>
<blockquote>
<div><p>Empirical log probability of features
given a class, <code class="docutils literal"><span class="pre">P(x_i|y)</span></code>.</p>
</div></blockquote>
<p><strong>coef_</strong> : property</p>
<blockquote>
<div><p>Mirrors <code class="docutils literal"><span class="pre">feature_log_prob_</span></code> for interpreting MultinomialNB
as a linear model.</p>
</div></blockquote>
<p><strong>class_count_</strong> : array, shape (n_classes,)</p>
<blockquote>
<div><p>Number of samples encountered for each class during fitting. This
value is weighted by the sample weight when provided.</p>
</div></blockquote>
<p><strong>feature_count_</strong> : array, shape (n_classes, n_features)</p>
<blockquote class="last">
<div><p>Number of samples encountered for each (class, feature)
during fitting. This value is weighted by the sample weight when
provided.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>For the rationale behind the names <cite>coef_</cite> and <cite>intercept_</cite>, i.e.
naive Bayes as a linear classifier, see J. Rennie et al. (2003),
Tackling the poor assumptions of naive Bayes text classifiers, ICML.</p>
<p class="rubric">References</p>
<p>C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to
Information Retrieval. Cambridge University Press, pp. 234-265.
<a class="reference external" href="http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html">http://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html</a></p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="k">import</span> <span class="n">MultinomialNB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">MultinomialNB</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">3</span><span class="p">]))</span>
<span class="go">[3]</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.fit" title="sklearn.naive_bayes.MultinomialNB.fit"><code class="xref py py-obj docutils literal"><span class="pre">fit</span></code></a>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Fit Naive Bayes classifier according to X, y</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.get_params" title="sklearn.naive_bayes.MultinomialNB.get_params"><code class="xref py py-obj docutils literal"><span class="pre">get_params</span></code></a>([deep])</td>
<td>Get parameters for this estimator.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.partial_fit" title="sklearn.naive_bayes.MultinomialNB.partial_fit"><code class="xref py py-obj docutils literal"><span class="pre">partial_fit</span></code></a>(X,&nbsp;y[,&nbsp;classes,&nbsp;sample_weight])</td>
<td>Incremental fit on a batch of samples.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.predict" title="sklearn.naive_bayes.MultinomialNB.predict"><code class="xref py py-obj docutils literal"><span class="pre">predict</span></code></a>(X)</td>
<td>Perform classification on an array of test vectors X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.predict_log_proba" title="sklearn.naive_bayes.MultinomialNB.predict_log_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_log_proba</span></code></a>(X)</td>
<td>Return log-probability estimates for the test vector X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.predict_proba" title="sklearn.naive_bayes.MultinomialNB.predict_proba"><code class="xref py py-obj docutils literal"><span class="pre">predict_proba</span></code></a>(X)</td>
<td>Return probability estimates for the test vector X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.score" title="sklearn.naive_bayes.MultinomialNB.score"><code class="xref py py-obj docutils literal"><span class="pre">score</span></code></a>(X,&nbsp;y[,&nbsp;sample_weight])</td>
<td>Returns the mean accuracy on the given test data and labels.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#sklearn.naive_bayes.MultinomialNB.set_params" title="sklearn.naive_bayes.MultinomialNB.set_params"><code class="xref py py-obj docutils literal"><span class="pre">set_params</span></code></a>(\*\*params)</td>
<td>Set the parameters of this estimator.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>alpha=1.0</em>, <em>fit_prior=True</em>, <em>class_prior=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/naive_bayes.py#L682"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/naive_bayes.py#L542"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit Naive Bayes classifier according to X, y</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional (default=None)</p>
<blockquote>
<div><p>Weights applied to individual samples (1. for unweighted).</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> : object</p>
<blockquote class="last">
<div><p>Returns self.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>deep=True</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L220"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>deep</strong> : boolean, optional</p>
<blockquote>
<div><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>params</strong> : mapping of string to any</p>
<blockquote class="last">
<div><p>Parameter names mapped to their values.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.partial_fit">
<code class="descname">partial_fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>classes=None</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/naive_bayes.py#L460"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.partial_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Incremental fit on a batch of samples.</p>
<p>This method is expected to be called several times consecutively
on different chunks of a dataset so as to implement out-of-core
or online learning.</p>
<p>This is especially useful when the whole dataset is too big to fit in
memory at once.</p>
<p>This method has some performance overhead hence it is better to call
partial_fit on chunks of data that are as large as possible
(as long as fitting in the memory budget) to hide the overhead.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : {array-like, sparse matrix}, shape = [n_samples, n_features]</p>
<blockquote>
<div><p>Training vectors, where n_samples is the number of samples and
n_features is the number of features.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = [n_samples]</p>
<blockquote>
<div><p>Target values.</p>
</div></blockquote>
<p><strong>classes</strong> : array-like, shape = [n_classes], optional (default=None)</p>
<blockquote>
<div><p>List of all the classes that can possibly appear in the y vector.</p>
<p>Must be provided at the first call to partial_fit, can be omitted
in subsequent calls.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional (default=None)</p>
<blockquote>
<div><p>Weights applied to individual samples (1. for unweighted).</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong> : object</p>
<blockquote class="last">
<div><p>Returns self.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/naive_bayes.py#L52"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform classification on an array of test vectors X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>C</strong> : array, shape = [n_samples]</p>
<blockquote class="last">
<div><p>Predicted target values for X</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/naive_bayes.py#L68"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Return log-probability estimates for the test vector X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>C</strong> : array-like, shape = [n_samples, n_classes]</p>
<blockquote class="last">
<div><p>Returns the log-probability of the samples for each class in
the model. The columns correspond to the classes in sorted
order, as they appear in the attribute <cite>classes_</cite>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/naive_bayes.py#L88"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Return probability estimates for the test vector X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = [n_samples, n_features]</p>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>C</strong> : array-like, shape = [n_samples, n_classes]</p>
<blockquote class="last">
<div><p>Returns the probability of the samples for each class in
the model. The columns correspond to the classes in sorted
order, as they appear in the attribute <cite>classes_</cite>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L324"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the mean accuracy on the given test data and labels.</p>
<p>In multi-label classification, this is the subset accuracy
which is a harsh metric since you require for each sample that
each label set be correctly predicted.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like, shape = (n_samples, n_features)</p>
<blockquote>
<div><p>Test samples.</p>
</div></blockquote>
<p><strong>y</strong> : array-like, shape = (n_samples) or (n_samples, n_outputs)</p>
<blockquote>
<div><p>True labels for X.</p>
</div></blockquote>
<p><strong>sample_weight</strong> : array-like, shape = [n_samples], optional</p>
<blockquote>
<div><p>Sample weights.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>score</strong> : float</p>
<blockquote class="last">
<div><p>Mean accuracy of self.predict(X) wrt. y.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="sklearn.naive_bayes.MultinomialNB.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>**params</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/9d3f127/sklearn/base.py#L257"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#sklearn.naive_bayes.MultinomialNB.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it&#8217;s possible to update each
component of a nested object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>self</strong> :</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<div class="section" id="examples-using-sklearn-naive-bayes-multinomialnb">
<h2>Examples using <code class="docutils literal"><span class="pre">sklearn.naive_bayes.MultinomialNB</span></code><a class="headerlink" href="#examples-using-sklearn-naive-bayes-multinomialnb" title="Permalink to this headline">¶</a></h2>
<div class="thumbnailContainer" tooltip="This is an example showing how scikit-learn can be used for classification using an out-of-core..."><div class="figure" id="id1">
<a class="reference external image-reference" href="./../../auto_examples/applications/plot_out_of_core_classification.html"><img alt="../../_images/plot_out_of_core_classification1.png" src="../../_images/plot_out_of_core_classification1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/applications/plot_out_of_core_classification.html#example-applications-plot-out-of-core-classification-py"><span class="std std-ref">Out-of-core classification of text documents</span></a></span></p>
</div>
</div><div class="thumbnailContainer" tooltip="This is an example showing how the scikit-learn can be used to classify documents by topics usi..."><div class="figure" id="id2">
<a class="reference external image-reference" href="./../../auto_examples/text/mlcomp_sparse_document_classification.html"><img alt="../../_images/mlcomp_sparse_document_classification1.png" src="../../_images/mlcomp_sparse_document_classification1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/text/mlcomp_sparse_document_classification.html#example-text-mlcomp-sparse-document-classification-py"><span class="std std-ref">Classification of text documents: using a MLComp dataset</span></a></span></p>
</div>
</div><div class="thumbnailContainer" tooltip="This is an example showing how scikit-learn can be used to classify documents by topics using a..."><div class="figure" id="id3">
<a class="reference external image-reference" href="./../../auto_examples/text/document_classification_20newsgroups.html"><img alt="../../_images/document_classification_20newsgroups1.png" src="../../_images/document_classification_20newsgroups1.png" /></a>
<p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py"><span class="std std-ref">Classification of text documents using sparse features</span></a></span></p>
</div>
</div><div class="clearer"></div></div>
</div>


          </div>
        </div>
      </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer">
        &copy; 2010 - 2014, scikit-learn developers (BSD License).
      <a href="../../_sources/modules/generated/sklearn.naive_bayes.MultinomialNB.txt" rel="nofollow">Show this page source</a>
    </div>
     <div class="rel">
    
    <div class="buttonPrevious">
      <a href="sklearn.naive_bayes.GaussianNB.html">Previous
      </a>
    </div>
    
     </div>

    
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-22606712-2']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    

    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript"> google.load('search', '1',
        {language : 'en'}); google.setOnLoadCallback(function() {
            var customSearchControl = new
            google.search.CustomSearchControl('016639176250731907682:tjtqbvtvij0');
            customSearchControl.setResultSetSize(google.search.Search.FILTERED_CSE_RESULTSET);
            var options = new google.search.DrawOptions();
            options.setAutoComplete(true);
            customSearchControl.draw('cse', options); }, true);
    </script>
  </body>
</html>